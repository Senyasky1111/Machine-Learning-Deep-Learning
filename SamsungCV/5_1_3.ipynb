{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMHGTjrVkhsi3FtU/EHGWgo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"a0OcLYu7Fv4e"},"outputs":[],"source":["import torch\n","from abc import ABC, abstractmethod\n","\n","\n","def calc_out_shape(input_matrix_shape, out_channels, kernel_size, stride, padding):\n","    batch_size, channels_count, input_height, input_width = input_matrix_shape\n","    output_height = (input_height + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n","    output_width = (input_width + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n","\n","    return batch_size, out_channels, output_height, output_width\n","\n","\n","class ABCConv2d(ABC):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride):\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","\n","    def set_kernel(self, kernel):\n","        self.kernel = kernel\n","\n","    @abstractmethod\n","    def __call__(self, input_tensor):\n","        pass\n","\n","\n","class Conv2d(ABCConv2d):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride):\n","        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n","                                      stride, padding=0, bias=False)\n","\n","    def set_kernel(self, kernel):\n","        self.conv2d.weight.data = kernel\n","\n","    def __call__(self, input_tensor):\n","        return self.conv2d(input_tensor)\n","\n","\n","def create_and_call_conv2d_layer(conv2d_layer_class, stride, kernel, input_matrix):\n","    out_channels = kernel.shape[0]\n","    in_channels = kernel.shape[1]\n","    kernel_size = kernel.shape[2]\n","\n","    layer = conv2d_layer_class(in_channels, out_channels, kernel_size, stride)\n","    layer.set_kernel(kernel)\n","\n","    return layer(input_matrix)\n","\n","\n","def test_conv2d_layer(conv2d_layer_class, batch_size=2,\n","                      input_height=4, input_width=4, stride=2):\n","    kernel = torch.tensor(\n","                      [[[[0., 1, 0],\n","                         [1,  2, 1],\n","                         [0,  1, 0]],\n","\n","                        [[1, 2, 1],\n","                         [0, 3, 3],\n","                         [0, 1, 10]],\n","\n","                        [[10, 11, 12],\n","                         [13, 14, 15],\n","                         [16, 17, 18]]]])\n","\n","    in_channels = kernel.shape[1]\n","\n","    input_tensor = torch.arange(0, batch_size * in_channels *\n","                                input_height * input_width,\n","                                out=torch.FloatTensor()) \\\n","        .reshape(batch_size, in_channels, input_height, input_width)\n","\n","    custom_conv2d_out = create_and_call_conv2d_layer(\n","        conv2d_layer_class, stride, kernel, input_tensor)\n","    conv2d_out = create_and_call_conv2d_layer(\n","        Conv2d, stride, kernel, input_tensor)\n","\n","    return torch.allclose(custom_conv2d_out, conv2d_out)\n","\n","\n","# Сверточный слой через циклы.\n","class Conv2dLoop(ABCConv2d):\n","    def __call__(self, input_tensor):\n","        batch_size, out_channels, output_height, output_width = calc_out_shape(\n","                                input_tensor.shape, \n","                                self.out_channels,\n","                                self.kernel_size,\n","                                self.stride,\n","                                padding=0)\n","            \n","        # создадим выходной тензор, заполненный нулями         \n","        output_tensor = torch.zeros(batch_size, out_channels, output_height, output_width)\n","        \n","        # вычисление свертки с использованием циклов.\n","        # цикл по входным батчам(изображениям)\n","        for num_batch, batch in enumerate(input_tensor): \n","             \n","            # цикл по фильтрам (количество фильтров совпадает с количеством выходных каналов)  \n","            for num_kernel, kernel in enumerate(self.kernel):\n","            \n","                # цикл по размерам выходного изображения\n","                for i in range(output_height):\n","                    for j in range(output_width): \n","                        \n","                        # вырезаем кусочек из батча (сразу по всем входным каналам)\n","                        current_row = self.stride*i\n","                        current_column = self.stride*j\n","                        current_slice = batch[:, current_row:current_row + self.kernel_size, current_column:current_column + self.kernel_size]\n","                        \n","                        # умножаем кусочек на фильтр\n","                        res = float((current_slice * kernel).sum())\n","                        \n","                        # заполняем ячейку в выходном тензоре\n","                        output_tensor[num_batch,num_kernel,i,j] = res\n","                        \n","        return output_tensor\n","\n","# Корректность реализации определится в сравнии со стандартным слоем из pytorch.\n","# Проверка происходит автоматически вызовом следующего кода\n","# (раскомментируйте для самостоятельной проверки,\n","#  в коде для сдачи задания должно быть закомментировано):\n","# print(test_conv2d_layer(Conv2dLoop))"]}]}